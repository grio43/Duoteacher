# Training data configuration

# This file contains the data‑specific parameters for the anime tagger
# training pipeline.  These values override defaults in
# ``SimplifiedDataConfig``.  In particular, random cropping is disabled by
# setting ``random_crop_scale`` to (1.0, 1.0), and ``pad_color`` is set
# to a neutral grey (114, 114, 114) to match the letterbox padding used
# during inference.  ``image_size`` must be divisible by ``patch_size`` to
# ensure that no pixels are lost when partitioning the image into
# non‑overlapping patches.

data:
  # Final square size to which images are resized before being split
  # into patches.  Must be divisible by ``patch_size``.
  image_size: 640
  # Size of each patch used by the vision transformer.  If
  # ``image_size`` is not a multiple of ``patch_size`` then additional
  # padding will be applied automatically.
  patch_size: 16
  # Disable random cropping so that images are not randomly cropped when
  # scaling down.  A scale of (1.0, 1.0) means the entire letterboxed
  # image is used.
  random_crop_scale: [1.0, 1.0]
  # Colour used for letterbox padding (RGB values in 0‑255 range).  A
  # neutral grey of 114 is commonly used for YOLO models.
  pad_color: [114, 114, 114]
  # Note: ``image_size`` must be divisible by ``patch_size`` to prevent
  # dropping edge pixels when partitioning into patches.
